\documentclass[11pt,a4paper]{article}

% Packages for formatting and layout
\usepackage{geometry}  % Adjust margins
\geometry{margin=0.7in}
\usepackage{setspace}  % For line spacing
\usepackage{graphicx, wrapfig}
\graphicspath{ {./assets/} }
\usepackage{amsmath}   % For mathematical expressions
\usepackage{hyperref}  % For hyperlinks
\usepackage{enumitem}  % For custom lists
\usepackage{listings}
\usepackage{subfigure}
\usepackage{xcolor}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

% Title information
\title{Predicting news truthfulness through graph-based retweet patterns.}
\author{Baggio Davide 2122547 \\ Martinez Zoren 2123873 \\ Brocheton Damien 2133034}
\date{}

\usepackage{etoolbox}
\makeatletter
\patchcmd{\@maketitle}{\null\vskip 2em}{}{}{}
\makeatother

\begin{document}

% Title Page
\maketitle

\section*{Motivation}

The rise of misinformation on social media has significant implications for public opinion, health, and safety, making it crucial to distinguish real news from fake. Twitter, as a major news source, often spreads information rapidly, sometimes without verification. By analyzing the graph structure of news propagation on Twitter, we can identify patterns in how real and fake news spread. This project aims to develop insights and tools to enhance the credibility of online information, contributing to a more informed and resilient public.
Recent studies\cite{rec_studies} have shown that machine learning models can effectively detect real or fake news by analyzing user-specific data, such as the profiles of those sharing the information. One of the biggest catches is the complexity of the generated models, mostly being Convolutional Neural Networks applied to Graphs and the low accuracy given new data. In this project, however, we aim to explore whether it’s possible to classify news as real or fake based solely on the "pure" retweet graph structure, independent of user metadata. By employing the algorithms outlined in the following sections, we will extract essential features from the retweet graph that can serve as inputs for a machine learning model, enabling an analysis based purely on the patterns of information spread.

\subsection*{Dataset}

The dataset is part of a bigger pool provided by the Twitter API. This part is shared on github under the Apache Licence, Version 2.0\cite{dataset}. The dataset is well documented in this paper\cite{data_paper}. It is basically a Graph with many connected components, each representing a news tree, composed of the main tweet of the news and all the retweets associated with it.

\section*{Method}

\subsection*{Problem}
Our objective is to identify the characteristics of tweets that reference a fake news, and determine if a new tweet references it by looking at its characteristics.
To analyze the dataset, we need to construct the graph from the dataset. The structure is represented as follows:
\newline
\begin{wrapfigure}{r}{0.5\textwidth}
	\begin{center}
	  \includegraphics[width=0.48\textwidth]{struct}
	\end{center}
\end{wrapfigure}
\begin{itemize}
	\setlength\itemsep{-0.3em}
	\item \textbf{Graph Type}: Tree-structured graphs
	\item \textbf{Root Node}: News item (labeled true/false)
	\item \textbf{Other Nodes}: Twitter users who retweeted the news
	\item \textbf{Edges}:
	\begin{itemize}
		\setlength\itemsep{-0.3em}
		\item News item $\leftrightarrow$ User: Direct retweet
		\item User $\leftrightarrow$ User: Retweet through an intermediary
	\end{itemize}
	\item \textbf{Additional Information}: Retweet timestamps
\end{itemize}

The goal is to extract features from the network and use that data to train a machine learning model to predict the truthfulness of news.
The algorithms that we are going to use are important for:
\begin{itemize}
	\setlength\itemsep{-0.3em}
	\item \textbf{Average depth of trees}: Is the depth of the trees greater for fake news?
	\item \textbf{Average retweet breadth}: Do fake news tend to spread more quickly having a greater breadth at the first level?
	\item \textbf{Average time between retweets}: Do fake news spread faster?
	\item \textbf{Peak diffusion time}: Do fake news have an explosive peak?
	\item \textbf{Users reliability score}: various features based on the ranking of users who shared the news
	\item \textbf{Centrality and Pagerank}: What nodes are more common to find in paths between other 2 nodes?
\end{itemize}

\section*{Intended Experiments}

\subsection*{User reliability ranking}
\begin{wrapfigure}{r}{0.5\textwidth}
	\begin{center}
	  \includegraphics[width=0.48\textwidth]{results}
	\end{center}
\end{wrapfigure}
One of the goal is to visualize wether new data involving a news fits better into the "Real news" or "Fake news" category. This can be achieve displaying a bar graph representing the features studied previously.\\
The final step is to create a ranking of users based on their reliability and to generate features for the data using this ranking. To do this, the following factors will be considered:
\begin{itemize}
	\setlength\itemsep{-0.3em}
	\item Number of retweets of false news
	\item Percentage of retweets of true vs. false news
	\item Betweenness centrality of the user in the graph
	\item Pagerank of the user in the graph
\end{itemize}

For large datasets computing the ranking for ALL users might be computationally expensive. Therefore, in this case, users with good centrality measures will have priority. 
The features of the news obtained from this ranking are as follows:
\begin{itemize}
	\setlength\itemsep{-0.3em}
	\item Average Ranking Positions of users who retweeted the news
	\item Percentage of reliable users (e.g. percentage of users in the top 20)
	\item Minimum and maximum position
	\item Weighted score based on reliability
\end{itemize}

\subsection*{Machine learning models}

The models we want to try are the following:
\begin{itemize}
	\setlength\itemsep{-0.3em}
	\item \textbf{Support Vector Machine}
	\item \textbf{Feed Forward Neural Network}
	\item \textbf{Random Forest}
\end{itemize}

We will make comparisons to better understand which model fits this problem best, based on which one achieves better accuracy and also the time it will take to train it.
\\\textbf{Libraries}: Networkx\cite{networkx} (for Graph analysis), Scikit-Learn\cite{scikit} (for SVM and RF models), Tensorflow\cite{tensor} (for FFNN model)
\\\textbf{Evaluation metrics of the model}: Accuracy, Precision, Recall and F1-Score
\\\textbf{Machine for experiments}: 
\begin{itemize}
	\setlength\itemsep{-0.3em}
	\item AMD Ryzen 5 3500U (8-cores), 8GB DDR4, Windows 11 or Ubunutu 20.04
	\item AMD Ryzen 5 4500 (8-cores), Radeon RX 6600, 16GB DDR4, Windows 11 or Ubuntu 20.04
\end{itemize}

\newpage

\section*{Development}

\subsection*{Extracting informations from the dataset}

The first part of the project involves extracting the data from the datatset. As shown previously the dataset is composed of many connected components, each representing a news (related to gossip or politics). It has been decided, during the development, to consider only few features that could be relevant to the objective of the project.
Those features are:\\\\
\textbf{Diameter}: provides insight into the maximum extent of information spread. The bigger the diameter, the deeper (given that the structure of the graph is a tree) the news is spreaded among the users.\\
\textbf{Maximum degree}: identifies the node with the highest number of connections. In the case of fake news, such nodes could be targeted for spreading misinformation widely.\\
\textbf{Degree centrality}: the number of direct connections a node has. Nodes with high degree centrality are crucial in the immediate dissemination of news.\\
\textbf{Closeness centrality}: how quickly information can spread from a given node to all other nodes in the network. High closeness centrality suggests that a node is well-positioned to efficiently spread news.\\
\textbf{PageRank}: rank of nodes in a graph based on their importance. High PageRank nodes are influential and could be key disseminators of real or fake news.\\
\textbf{Average Standard Deviation of Retweet Timestamps}: consistency or burstiness of retweet activity over time. A small average standard deviation means that the news could be spreaded in a small amount of time since it has been tweeted for the first time.\\

Using networkx\cite{networkx} as the library for analyzing the graphs, extracting these information was actually easy. With all the features we then exported them into ".csv" files and ultimately we calculated all the average values separately for news labeled real and fake that are going to be used later in a system of prediction based on score.

\begin{lstlisting}[language=Python]
    import networkx as nx

    #calculating std of the timestamps
    std = np.std(np.array(timestamps))
    #calculating the diameter
    d = nx.diameter(s.graph)
    #calculating the max degree
    _, neighbors = max(s.graph.degree, key=lambda x: x[1])
    #calculating degree centrality
    dc = np.mean(list(nx.degree_centrality(s.graph).values()))
    #calculating closeness centrality
    cc = np.mean(list(nx.closeness_centrality(s.graph).values()))
    #calculating pagerank
    pr = np.mean(list(nx.pagerank(s.graph).values()))
\end{lstlisting}

\newpage

\subsection*{Prediction system}

Once the features are extracted we have created a system based on score that is capable of predicting in a probabilistic way if a news is real or fake. This system gets some graphs data as input
and determines how much it deviates from the averages calculated with previous algorithms giving a final score from 0 to 12 (12 being the highest confidence).

\begin{lstlisting}[language=Python]
	def confidence_scoring(value, avg_r, avg_f):
        # Compute the difference
        diff_r = abs(avg_r - value)    #avg of real sub-graph - new value
        diff_f = abs(avg_f - value)    #avg of fake sub-graph - new value
        inside = (value<avg_r and value>avg_f) or (value<avg_f and value>avg_r) #The value is between the 2 avg
        #Closest one
        closer = 0              # 0 = Equal
        if diff_r < diff_f:
            closer = 1          # 1 = Real
        elif diff_r > diff_f:
            closer = 2          # 2 = Fake
        #Confidence score
        score = 0                                       #No guess
        if closer == 1:                                 #Real
            if 2*diff_r < diff_f or not inside:
                score = 2                               #Strong guess
            else:
                score = 1                               #Weak guess
        elif closer == 2:                               #Fake
            if 2*diff_f < diff_r or not inside:
                score = -2                              #Strong guess
            else:
                score = -1                              #Weak guess
        return score
\end{lstlisting}

\begin{center}
	\includegraphics[width=0.8\textwidth]{graph}
\end{center}

The image above is just an example on how it can display the prediction and its accuracy. It represent
a conﬁdence score on how sure we are about a news label. From what we can see, there is a correlation between the data extracted from
the graphs and their actual label. This is what we expected from the beginning so this will be important to develop a machine learning model which is able to predict the truthfulness of a news with a sufficiently high accuracy.

\newpage

\subsection*{Machine learning models and User reliability ranking}

In the final part of the project some ML models have been developed and tested onto the features retrieved before. By using the dataset we were able to map the nodes ID to the user ID and determine the number of real and fake news retweeted by the users. We then calculated the user score with this equation:

\begin{center}
	UserScore = US \\
	Normalized number of false retweets = FR \\
	Normalized true to false ratio = TFR \\
	Normalized pagerank of node = NP \\
	Normalized degree centrality of node = NP \\
	Normalized closeness centrality of node = NP \\
\end{center}

\begin{equation}
	US = 0.4 \times FR + 0.3 \times TFR + 0.2 \times NP + 0.1 \times DC + 0.1 \times CC
\end{equation}

\begin{lstlisting}[language=Python]
	# Calculate the score for each user
    # Calculate FR (False Retweets)
    FR = user["FalseNews"] / user["TotalNews"] 
        if user["TotalNews"] > 0 else 0
    # Calculate TFR (True to False Ratio)
    TFR = user["TrueNews"] / user["FalseNews"] 
        if user["FalseNews"] > 0 else user["TrueNews"]
    # Calculate NP (PageRank)
    NP = (user["PageRankCentrality"] - min_pr) / (max_pr - min_pr) 
        if max_pr != min_pr else 0
    # Calculate DC (Degree Centrality)
    DC = (user["DegreeCentrality"] - min_dc) / (max_dc - min_dc) 
        if max_dc != min_dc else 0
    # Calculate CC (Closeness Centrality)
    CC = (user["ClosenessCentrality"] - min_cc) / (max_cc - min_cc) 
        if max_cc != min_cc else 0
    # Penalize users with low TotalNews
    penalty = alpha / user["TotalNews"] if user["TotalNews"] > 0 else 0
    # Calculate UserScore
    user["UserScore"] = 0.4 * FR + 0.3 * TFR + 0.1 * NP + 0.1 * DC + 0.1 * CC
\end{lstlisting}

This user ranking will be useful later to train some models in order to increase the general accuracy. As stated before we are going to implement three type of ML models: Support Vector Machine, Feed Forward Neural Network and Random Forest of which all have been tuned with a validation set to have the best parameters.
The final question is: how well does these model perform on the features extracted before?

\newpage

\subsection*{Results}

\begin{figure}[h]
    \centering
    \subfigure[Random Forest Results]{
        \includegraphics[width=0.4\textwidth]{rf_results}
    }
    \subfigure[Feed Forward Neural Network Results]{
        \includegraphics[width=0.4\textwidth]{ffnn_results}
    }
    \subfigure[Support Vector Machine Results]{
        \includegraphics[width=0.4\textwidth]{svm_no_ranking_result}
    }
\end{figure}

The Support Vector Machine results were promising even though the model is very simple, requires few resources and the training is not time consuming. We then tried to concatenate the User ranking data to the features of the news graph and feed them into another SVM model with the same parameters as the one used in figure (a). The results were impressive:

\begin{figure}[h]
    \centering
    \subfigure[Support Vector Machine with ranking Results]{
        \includegraphics[width=0.6\textwidth]{svm_ranking_result.png}
    }
\end{figure}

\section*{Issues encountered}

\newpage

\begin{thebibliography}{9}
	\bibitem{rec_studies} Yi Han, Shanika Karunasekeran, Christopher Leckie\\"Graph Neural Networks with Continual Learning for Fake News Detection from Social Media",\\ \url{https://arxiv.org/pdf/2007.03316}, 2020.
	\bibitem{dataset} Dataset: \url{https://github.com/safe-graph/GNN-FakeNews/tree/main},\\\url{https://drive.google.com/drive/folders/1OslTX91kLEYIi2WBnwuFtXsVz5SS_XeR?usp=sharing}
	\bibitem{data_paper} Kai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee and Huan Liu\\"FakeNewsNet: A Data Repository with News Content, Social Context and Spatiotemporal Information for Studying Fake News on Social Media",\\ \url{https://arxiv.org/pdf/1809.01286}, 2019
	\bibitem{networkx} NetworkX library: \url{https://networkx.org/documentation/stable/}
	\bibitem{scikit} Scikit-learn library: \url{https://scikit-learn.org/stable/api/index.html}
	\bibitem{tensor} Tensorflow library: \url{https://www.tensorflow.org/api_docs/python/tf}
\end{thebibliography}

\newpage

\section*{Contribution}
Contributors:
\begin{itemize}
	\setlength\itemsep{-0.3em}
	\item Baggio Davide ($\frac{1}{3}$ of the work): Finding a well documented dataset, reading the related papers and understanding it. Writing the first part of the proposal and preprocessing the dataset ready for analysis into a python script.
	\item Martinez Zoren ($\frac{1}{3}$ of the work): Finding a well documented dataset,  reading the related papers and understanding it. Writing the third part of the proposal and planning on the machine learning models to use in order to achieve the goal of the project.
	\item Brocheton Damien ($\frac{1}{3}$ of the work): Finding a well documented dataset,  reading the related papers and understanding it. Writing the second part of the proposal and starting to write the postprocessing of the data into a python script that compare new data with the studied one using a probabilistic algorithm.
\end{itemize}

\end{document}
